{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install streamlit pyngrok PyPDF2 langchain transformers huggingface_hub sentence-transformers\n"
      ],
      "metadata": {
        "id": "wNKESmxlorlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import streamlit as st\n",
        "from dotenv import load_dotenv\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from transformers import pipeline\n",
        "from langchain.llms import HuggingFaceHub\n",
        "\n",
        "\n",
        "# Ã‡alÄ±ÅŸan Streamlit uygulamasÄ±nÄ± durdur\n",
        "ngrok.kill()\n",
        "\n",
        "# Ã‡alÄ±ÅŸtÄ±rÄ±lacak portu ayarla\n",
        "port = 8501\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print(f\"ðŸ“¢ Public URL: {public_url}\")\n",
        "\n",
        "# Huggingface iÃ§in token yÃ¼kleme\n",
        "from huggingface_hub import login\n",
        "\n",
        "# Hugging Face Token'Ä±nÄ± Buraya Gir\n",
        "HUGGINGFACE_TOKEN = \"",
        "login(token=HUGGINGFACE_TOKEN)\n",
        "\n",
        "# PDF DosyasÄ±ndan Metin Ã‡Ä±karma Fonksiyonu\n",
        "def get_pdf_text(pdf_docs):\n",
        "    text = \"\"\n",
        "    for pdf in pdf_docs:\n",
        "        pdf_reader = PdfReader(pdf)\n",
        "        for page in pdf_reader.pages:\n",
        "            text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "\n",
        "# Metni ParÃ§alara BÃ¶lme (Chunking)\n",
        "def get_text_chunks(text):\n",
        "    text_splitter = CharacterTextSplitter(\n",
        "        separator=\"\\n\",\n",
        "        chunk_size=1000,\n",
        "        chunk_overlap=200,\n",
        "        length_function=len\n",
        "    )\n",
        "    chunks = text_splitter.split_text(text)\n",
        "    return chunks\n",
        "\n",
        "\n",
        "# VektÃ¶r VeritabanÄ± OluÅŸturma\n",
        "def get_vectorstore(text_chunks):\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "    vectorstore = FAISS.from_texts(texts=text_chunks, embedding=embeddings)\n",
        "    return vectorstore\n",
        "\n",
        "\n",
        "# KonuÅŸma Zinciri OluÅŸturma\n",
        "def get_conversation_chain(vectorstore):\n",
        "    # Meta-Llama modelini baÅŸlatma\n",
        "    llm = HuggingFaceHub(\n",
        "        repo_id=\"meta-llama/Llama-3.2-3B-Instruct\",\n",
        "        model_kwargs={\"temperature\": 0.5, \"max_length\": 512}\n",
        "    )\n",
        "\n",
        "    memory = ConversationBufferMemory(\n",
        "        memory_key='chat_history',\n",
        "        return_messages=True\n",
        "    )\n",
        "\n",
        "    conversation_chain = ConversationalRetrievalChain.from_llm(\n",
        "        llm=llm,\n",
        "        retriever=vectorstore.as_retriever(),\n",
        "        memory=memory\n",
        "    )\n",
        "    return conversation_chain\n",
        "\n",
        "\n",
        "# KullanÄ±cÄ± SorularÄ±nÄ± Ä°ÅŸleme Fonksiyonu\n",
        "def handle_userinput(user_question):\n",
        "    response = st.session_state.conversation({'question': user_question})\n",
        "    st.session_state.chat_history = response['chat_history']\n",
        "\n",
        "    for i, message in enumerate(st.session_state.chat_history):\n",
        "        if i % 2 == 0:\n",
        "            st.markdown(f\"**KullanÄ±cÄ±:** {message.content}\")\n",
        "        else:\n",
        "            st.markdown(f\"**Bot:** {message.content}\")\n",
        "\n",
        "\n",
        "# Ana Uygulama Fonksiyonu\n",
        "def main():\n",
        "    # Ã‡evre deÄŸiÅŸkenlerini yÃ¼kle\n",
        "    load_dotenv()\n",
        "\n",
        "    # Sayfa baÅŸlÄ±ÄŸÄ± ve favicon\n",
        "    st.set_page_config(page_title=\"PDF Chatbot\", page_icon=\"ðŸ“„\")\n",
        "\n",
        "    st.title(\"ðŸ“„ Birden Fazla PDF ile Sohbet Edin!\")\n",
        "    st.write(\"PDF dosyalarÄ±nÄ±zÄ± yÃ¼kleyin ve akÄ±llÄ± asistan ile sohbet edin.\")\n",
        "\n",
        "    # Uygulama Durumu BaÅŸlatma\n",
        "    if \"conversation\" not in st.session_state:\n",
        "        st.session_state.conversation = None\n",
        "    if \"chat_history\" not in st.session_state:\n",
        "        st.session_state.chat_history = None\n",
        "\n",
        "    # KullanÄ±cÄ±dan Soru Alma\n",
        "    user_question = st.text_input(\"Belgelerinizle ilgili bir soru sorun:\")\n",
        "    if user_question:\n",
        "        handle_userinput(user_question)\n",
        "\n",
        "    with st.sidebar:\n",
        "        st.subheader(\"ðŸ“‚ DosyalarÄ±nÄ±zÄ± YÃ¼kleyin\")\n",
        "        pdf_docs = st.file_uploader(\n",
        "            \"PDF dosyalarÄ±nÄ±zÄ± buraya yÃ¼kleyin ve ardÄ±ndan 'Ä°ÅŸle' butonuna tÄ±klayÄ±n.\",\n",
        "            accept_multiple_files=True\n",
        "        )\n",
        "\n",
        "        if st.button(\"ðŸ“Œ Ä°ÅŸle\"):\n",
        "            with st.spinner(\"ðŸš€ Ä°ÅŸleniyor...\"):\n",
        "                # PDF'ten metin Ã§Ä±karma\n",
        "                raw_text = get_pdf_text(pdf_docs)\n",
        "\n",
        "                # Metni parÃ§alara bÃ¶lme (chunking)\n",
        "                text_chunks = get_text_chunks(raw_text)\n",
        "\n",
        "                # VektÃ¶r veritabanÄ± oluÅŸturma\n",
        "                vectorstore = get_vectorstore(text_chunks)\n",
        "\n",
        "                # KonuÅŸma zinciri baÅŸlatma\n",
        "                st.session_state.conversation = get_conversation_chain(vectorstore)\n",
        "\n",
        "                st.success(\"âœ… Ä°ÅŸlem tamamlandÄ±! Åžimdi sorularÄ±nÄ±zÄ± sorabilirsiniz.\")\n",
        "\n",
        "# Streamlit'i Ã§alÄ±ÅŸtÄ±rma iÅŸlevi\n",
        "def start_streamlit():\n",
        "    os.system(\"streamlit run app.py\")\n",
        "\n",
        "# UygulamayÄ± arka planda Ã§alÄ±ÅŸtÄ±r\n",
        "thread = threading.Thread(target=start_streamlit)\n",
        "thread.start()\n",
        "\n",
        "# UygulamayÄ± baÅŸlat\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "d4rM8A2ppMFU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
